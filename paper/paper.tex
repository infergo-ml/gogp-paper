\documentclass[sigplan,review,10pt,anonymous]{acmart}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{hyperref}
\usepackage{courier}
\usepackage{listings}[language=Golang]

\lstdefinelanguage{Golang}%
  {morekeywords=[1]{package,import,func,type,struct,return,defer,panic,%
     recover,select,var,const,iota,},%
   morekeywords=[2]{string,uint,uint8,uint16,uint32,uint64,int,int8,int16,%
     int32,int64,bool,float32,float64,complex64,complex128,byte,rune,uintptr,%
     error,interface},%
   morekeywords=[3]{map,slice,make,new,nil,len,cap,copy,close,true,false,%
     delete,append,real,imag,complex,chan,},%
   morekeywords=[4]{for,break,continue,range,go,goto,switch,case,fallthrough,if,%
     else,default,},%
   morekeywords=[5]{Println,Printf,Error,Print,},%
   sensitive=true,%
   morecomment=[l]{//},%
   morecomment=[s]{/*}{*/},%
   morestring=[b]',%
   morestring=[b]",%
   morestring=[s]{`}{`},%
} 

\lstset{ % add your own preferences
    frame=none,
    basicstyle=\ttfamily,
    numbers=left,
    numbersep=5pt,
    showstringspaces=false,
    tabsize=4,
    language=Golang % this is it !
}


\acmConference[Onward! 2019]{SPLASH Onward! 2019}{October 20-25, 2019}{Athens, Greece}

% Copyright
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


\bibliographystyle{ACM-Reference-Format}

\title{Deployable Probabilistic Programming}
\author{David Tolpin}
\affiliation{
    \institution{PUB+}
    \country{Israel}
}
\email{david.tolpin@gmail.com}

\begin{abstract}
	We share our experiences from integrating probabilistic
	programming into a server-side software system and introduce
	a probabilistic programming facility for Go, a modern
	programming language of choice for server-side software
	development. We demonstrate how a lightweight but powerful
	and efficient probabilistic programming facility can be
	added to an existing programming language.  Server-side
	application of probabilistic programming poses challenges
	for a probabilistic programming system. We discuss the
	challenges and our experience in overcoming them, and
	suggest guidelines that can help in a wider adoption of
	probabilistic programming in server-side software systems.
\end{abstract}

\begin{document}
\maketitle

\begin{sloppypar}

\section{Introduction}

	Probabilistic programming \cite{GMR+08,MSP14,WVM14,GS15}
	represents statistical models as programs written in an
	otherwise general programming language that provides syntax
	for the definition and conditioning of random variables.
	Inference can be performed on probabilistic programs to
	obtain the posterior distribution or point estimates of the
	variables. Inference algorithms are provided by the
	probabilistic programming system, and each algorithm is
	usually applicable to a wide class of probabilistic programs
	in a black box manner.  Inference techniques provided by the
	system back end, such as Metropolis-Hastings
	\cite{WSG11,MSP14,YHG14}, Hamiltonian Monte Carlo
	\cite{SDT14}, expectation propagation \cite{MWG+10},
	extensions of Sequential Monte Carlo
	\cite{WVM14,MYM+15,PWD+14}, variational inference~\cite{},
	gradient-based optimization~\cite{}, and others.

	There are two polar views on the role of probabilistic
	programming.  One view is that probabilistic programming is
	a flexible framework for specification and analysis of
	statistical models.  Proponents of this view perceive
	probabilistic programming as a tool for data science
	practitioners. A typical work flow consists of data
	acquisition and pre-processing, followed by several
	iterations of exploratory model design and testing of
	inference algorithms. Once a sufficiently robust statistical
	model is obtained, analysis results are post-processed,
	visualized, and occasionally integrated into algorithms of a
	production software system. 

	The other, emerging, view is that probabilistic programming
	is an extension to a regular programming toolbox allowing
	algorithms implemented in general programming languages to
	have learnable parameters. In this view, statistical models
	are integrated into the software system, and inference and
	optimization take place during data processing, prediction,
	and algorithmic decision making in production.
	Probabilistic programming code runs unattended, and
	inference results are an integral part of the algorithms.

	In this work we are concerned with the later view on
	probabilistic programming. Our objective is to pave a path
	to deployment of probabilistic programs in production
	systems, promoting a wider adoption of probabilistic
	programming as a flexible tool for ubiquitous statistical
	inference. Most probabilistic programming systems are
	suited, to a certain extent, to be used in either the
	exploratory or the production scenario. However, the
	proliferation of probabilistic programming languages and
	systems~\cite{} one one hand, and scarcity of success
	stories about production use of probabilistic programming on
	the other hand, suggest that there is a need for new ideas
	and approaches to make probabilistic programming models
	available for production use.

	Our attitude differs from the established approach in that
	instead of proposing yet another probabilistic programming
	language, either genuinely different~\cite{} or derived from
	an existing general programming language by extending the
	syntax or changing the semantics~\cite{}, we advocate
	enabling probabilistic inference on models written in a
	general probabilistic programming language, the same one as
	the language used to program the bulk of the system. We
	formulate guidelines for such implementation, and based on
	the guidelines, introduce a probabilistic programming
	facility for the Go programming language. By explaining our
	design choices and implementation techniques, we argue that
	a similar facility can be added to any modern general
	purpose programming language, giving a production system
	modeling and inference capabilities which do not fall short
	from and sometimes exceed those of probabilistic programming
	centric systems with custom languages and runtimes.

	\subsection*{Contributions}

	This work brings the following major contributions:

	\begin{itemize}
		\item Guidelines for design and implementation of a
			probabilistic programming facility deployable as a part 
			of production software systems.
		\item A reference implementation of deployable probabilistic
			programming facility for the Go programming language.
		\item Design and implementation highlights outlining
			important choices we made in implementation of the
			probabilistic programming facility, and providing a
			basis for implementation of a similar facility for
			other general programming languages.
	\end{itemize}

\section{Related Work}

\section{Challenges}

Incorporating a probabilistic program, or rather a probabilistic
procedure, within a larger code body appears to be rather
straightforward: one implements the model in the probabilistic
programming language, fetches and preprocesses the data in the
host programming language, passes the data and the model to an
inference algorithm, and post-processes the results in the
host programming language again to make algorithmic
decisions based on inference outcomes. However, complex
server-side software systems make integration of probabilistic
inference challenging. 

\paragraph{Simulation vs. inference} Probabilistic models
often follow a design pattern of simulation-inference: a
significant part of the model is a simulator, running an
algorithm with fixed parameters; the optimal parameters, or
their distribution, are to be inferred. The inferred parameters
are then used by the software system to execute the simulation
independently of inference for forecasting and decision making.

This pattern suggests re-use of the simulator: instead of
implementing the simulator twice, in the probabilistic model and
in the host environment, the same code can serve both purposes.
However to achieve this, the host language must coincide with
the implementation language of the probabilistic model, on one
hand, and allow a computationally efficient implementation of
the simulation, on the other hand. Some probabilistic systems
(Figaro~\cite{P09}, Anglican~\cite{TMY+16}, Turing~\cite{GXG18})
are built with tight integration with the host environment in
mind; more often than not though the probabilistic code is
not trivial to re-use.

\paragraph{Data interface} In a server-side application data
for inference comes from a variety of sources: network,
databases, distributed file systems, and in many different
formats. Efficient inference depends on fast data access and
updating. Libraries for data access and manipulation are
available in the host environment. While the host environment
can be used as a proxy retrieving and transforming the data,
such as in the case of Stan~\cite{Stan17} integrations,
sometimes direct access from the probabilistic code is the
preferred option, for example when the data is streamed or
retrieved conditionally. 

\paragraph{Integration and deployment} Deployment of server-side
software systems is a delicate process involving automatic
builds and maintenance of dependencies. Adding  a component,
which possibly introduces additional software dependencies or
even a separate runtime, complicates deployment. Minimizing the
burden of probabilistic programming on the integration
and deployment process should be a major consideration in
design or selection of probabilistic programming tools.
Probabilistic programming systems that are implemented or 
provide an interface in a popular programming language, e.g.
Python (Edward~\cite{THS+17}, Pyro~\cite{Pyro18}) are easier
to integrate and deploy, however the smaller the footprint
of a probabilistic system, the easier is the adoption.

\section{Guidelines}

Based on the experience of developing and deploying solutions
using different probabilistic environments, we came up with
guidelines to implementation of a probabilistic programming
facility for server-side applications. We believe that these
guidelines, when followed, help easier integration of
probabilistic programming inference into large-scale server-side
software systems.

\begin{enumerate}
\item A probabilistic model should be programmed in the host
programming language. The facility may impose a discipline on
model implementation, such as through interface constraints, but
otherwise supporting unrestricted use of the host language for
implementation of the model.

\item Built-in and user-defined data structures and libraries
should be accessible in the probabilistic programming model.
Inference techniques relying on the code structure, such as
those based on automatic differentiation, should support the
use of common data structures of the host language.

\item The model code should be reusable between inference and
simulation. The code which is not required solely for inference
should be written once for both inference of parameters and use
of the parameters in the host environment.  It should be
possible to run simulation outside the probabilistic model without
runtime or memory overhead imposed by inference needs.
\end{enumerate}

\section{Probabilistic Programming in Go}

In line with the guidelines, we have implemented a probabilistic
programming facility for the Go programming language, Infergo.
%(\url{http://infergo.ml/}). 
We have chosen Go because Go is a
small but expressive programming language with efficient
implementation, which has recently become quite popular for
computation-intensive server-side programming. Infergo is
used in production environment for inference of mission-critical
algorithm parameters.

\subsection{An Overview of Infergo}

A probabilistic model in Infergo is an implementation of an
interface requiring a single method \lstinline{Observe} which
accepts a vector (a Go \textit{slice}) of floats, the parameters
to infer, and returns a single float, interpreted as
unnormalized log-likelihood of the posterior distribution.
Implementation of model methods can be written in virtually
unrestricted Go and use any Go libraries.

For inference, Infergo relies on automatic differentiation. The
source code of the model is translated by a command-line tool
provided by Infergo into an equivalent model with reverse-mode
automatic differentiation of the log-likelihood with respect to
the parameters applied. The differentiation operates on the
built-in floating-point type and incurs only a small
computational overhead. However, even this overhead is avoided
when the model code is executed outside of inference algorithms:
both the original and the differentiated model are
simultaneously available to the rest of the program code, so the
methods can be called on the differentiated model for inference,
and on the original model for the most efficient execution with
the inferred parameters.

The Go programming language and development environment offer
capabilities which made implementation of Infergo affordable.

\begin{itemize}
\item The Go parser and abstract syntax tree serializer are
	a part of the standard library. Parsing, transforming,
	and generating Go source code is straightforward and
	effortless.
\item Type inference (or \textit{type checking} as it is
	called in the Go ecosystem), also provided in the
	standard library, augments parsing and allows to
	selectively apply transformation-based automatic
	differentiation  based on static expression types. 
\item Go compiles and runs fast. Fast compilation and
	execution speeds allow to use the same facility for both
	exploratory design of probabilistic models and for
	inference in production environment.
\item Go offers efficient parallel execution as a
	first-class feature, via so-called \textit{goroutines}.
	Goroutines streamline implementation of sampling-based
	inference algorithms. Sample generators and consumers
	are run in parallel, communicating through channels. 
	Inference is easy to parallelize in order to exploit
	hardware multi-processing, and samples are retrieved
	lazily for postprocessing. 
\end{itemize}

\subsection{Probabilistic ``Hello, World!''}

TODO: Example

\section{Model Syntax and Rules of Differentiation}

A model is defined in it's own package. The model must
implement interface \lstinline{Model} containing a single method
\lstinline{Observe}. \lstinline{Observe} accepts receives a slice of
\lstinline{float64} --- the model parameters --- and returns a
\lstinline{float64} scalar. For probabilistic inference, the
returned value is interpreted as the log-likelihood of the model
parameters. In the model's source code:

\begin{enumerate}
	\item Methods on the type implementing \lstinline{Model} returning a
		single \lstinline{float64} or nothing are differentiated.
	\item Within the methods, the following is differentiated:
		\begin{itemize}
			\item assignments to \lstinline{float64} (including parallel
				assignments if all values are of type
				\lstinline{float64});
			\item returns of \lstinline{float64};
			\item standalone calls to methods on the type implementing
				\lstinline{Model} (apparently called for side  effects on
				the model).
		\end{itemize}
\end{enumerate}

Derivatives do not propagate through a function that is not
an elemental or a call to a model method. If a derivative is
not registered for an elemental, calling the elemental in a
differentiated context will cause a run-time error.

\subsection{Elementals}

Functions are considered elementals (and must have a
registered derivative) if their signature is of kind
\lstinline{func (float64, float64*) float64}; that is, 
one or more non-variadic \lstinline{float64} arguments and
\lstinline{float64} return value. For example, function
\lstinline{func (float64, float64, float64) float64}
is considered elemental, while functions

\begin{itemize}
	\item \lstinline{func (...float64) float64}
	\item \lstinline{func ([]float64) float64}
	\item \lstinline{func (int, float64) float64}
\end{itemize}

are not. Gradients for selected functions from the \lstinline{math}
package are pre-defined (\lstinline{Sqrt}, \lstinline{Exp}, \lstinline{Log}, \lstinline{Pow}, \lstinline{Sin},
\lstinline{Cos}, \lstinline{Tan}). Auxiliary elemental functions with pre-defined
gradients are provided in a separate package.

\section{Design and Implementation Highlights}

\subsection{Choice of Programming Language}

\subsection{Automatic Differentiation}

\subsection{Inference}

\subsubsection{Optimization}

\subsubsection{Full Posterior}

\subsection{Composability of Models}

\subsection{Stochasticity and Streaming}

\section{Case Studies}

\subsection{Performance}

Table~\ref{tab:memory-runtime} provides memory consumption and
running time measurements on basic models to illustrate
Infergo's performance.  The measurements were obtained on a
2.3GHz Intel Core 5 CPU with 8GB of memory for 1000 iterations
of Hamiltonian Monte Carlo with 10 leapfrog steps. Note that
log-likelihood computation for standard distributions is not
optimized yet. Quite the opposite: since models in Infergo are
fully composable, primitive distributions are themselves
implemented as Infergo models and automatically differentiated.

{\smaller
\begin{table}[H]
\caption{Memory and running times for 1000 iterations
of HMC with 10 leapfrog steps.}
\label{tab:memory-runtime}
\begin{tabular}{r | c |  c | c}
	{\it model}  & \multicolumn{2}{c|}{\it time} & {\it memory} \\ 
	 & {\it compilation} & {\it execution} & \\\hline
	8 schools & 0.15s & 0.6s & 5.5MB \\
	10D normal, 100 points & 0.15s & 3.0s & 5.7MB \\
	50D normal, 100 points & 0.15s & 13.0s & 5.8MB 
\end{tabular}
\end{table}}

\section{Conclusion}

A lightweight probabilistic programming facility similar to
Infergo can be added to most modern general-purpose programming
languages, in particular those used in implementing large-scale
software systems, making probabilistic programming inference
more accessible in server-side applications.

\section*{Acknowledgements}

The author owes a debt of gratitude to Frank Wood who introduced
the author to probabilistic programming and inspired to
pursue probabilistic programming paradigms and applications. The
author also would like to thank Jan-Willem van de Meent, with
whom the author had fruitful discussions of motives, ideas, and
implementation choices behind Infergo, and whose thoughts and
recommendations significantly influenced Infergo design.
Finally, the author thanks PUB+, the company the author works
for, for supporting development of Infergo and letting the
author experiment with applying probabilistic programming to
critical decision-making in production environment.

\end{sloppypar}

\bibliography{refs}

\end{document}
